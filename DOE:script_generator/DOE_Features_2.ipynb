{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DOE: Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Note: This notebook just generates potential experiment groups of different sizes (k) - final experiment groups were chosen manually (see excel sheet)\n",
    "\n",
    "#### Description:\n",
    "\n",
    "1) Read in language vectors and their dataset abbreviation\n",
    "\n",
    "2) Remove investigated feature from the dataframe and find k closest vectors for feature\n",
    "\n",
    "3) Create overview over all features for k\n",
    "\n",
    "4) Generate for each k a csv-file -> experiment groups are chosen manually in excel\n",
    "\n",
    "5) Create scripts per feature from manual choice (csv-file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5) Generate experiment script files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doe is the table with features as a dataframe\n",
    "def df_per_feature(doe, feat_number):\n",
    "    feature =\"Feature \"+str(feat_number)\n",
    "    feat_1 = doe['FEATURE'] == feature \n",
    "    return doe[feat_1]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from language similarity\n",
    "\n",
    "def generate_script_file(doe):\n",
    "    \n",
    "#     df = dist_filter(df_raw, d)\n",
    "#     print(df)\n",
    "#     number_of_experiments = df['DIST'].value_counts().sort_index()[d]\n",
    "    #concatenation\n",
    "# false_lan_list = .. \n",
    "# true_lan_list = ..\n",
    "# eval_list = ..\n",
    "\n",
    "    for i in range(13,14):\n",
    "        df = df_per_feature(doe,i)\n",
    " \n",
    "        false_lan_list = df['FALSE - Experiment group'].to_list()  \n",
    "        false_lan_list  = [x for x in false_lan_list  if str(x) != 'nan'] \n",
    "        \n",
    "        eval_list = df['Evaluation 1'].to_list() \n",
    "        eval_list  = [x for x in eval_list  if str(x) != 'nan']\n",
    "        \n",
    "        true_no_eval_lan_list = df['True no eval'].to_list() \n",
    "        true_no_eval_lan_list  = [x for x in true_no_eval_lan_list  if str(x) != 'nan'] \n",
    "               \n",
    "        \n",
    "        file = open('../experiments/feature_'+str(i)+'/run_transformers.sh','w')\n",
    "        #file = open('run_transformers.sh','w')\n",
    "\n",
    "        file.write('# @author: jopo, phze \\n')\n",
    "        file.write('# @date: ' + str(datetime.datetime.now()) + '\\n')\n",
    "        file.write('\\n')\n",
    "        file.write('\\n') \n",
    "        \n",
    "        # do it for four experiments: \n",
    "        for experiment in range(1,5):\n",
    "            file.write('\\n')\n",
    "            file.write('\\n')\n",
    "            file.write(\"# Experiment\" +str(experiment)+\"\\n\")\n",
    "            file.write('\\n') \n",
    "            file.write(\"cat\")\n",
    "            for j in false_lan_list:\n",
    "                file.write(\" 'languages/\" + j + \"/dataset_\"+str(experiment)+\".txt'\")#some_df[i] lists languages for finetuning1 \n",
    "            file.write(\"> 'languages/f\" + str(i) +  \"/dataset_false_lan.txt'\\n\")\n",
    "\n",
    "            file.write(\"cat\")\n",
    "            for j in eval_list:\n",
    "                file.write(\" 'languages/\" + j +\"/dataset_\"+str(experiment)+\".txt'\")\n",
    "            file.write(\"> 'languages/f\" + str(i) +  \"/dataset_eval.txt'\\n\")#some_other_df[i] lists languages for finetuning2 \n",
    "\n",
    "            file.write(\"cat\")\n",
    "            for j in true_no_eval_lan_list:\n",
    "                file.write(\" 'languages/\" + j +\"/dataset_\"+str(experiment)+\".txt'\")\n",
    "            file.write(\"> 'languages/f\" + str(i) +  \"/dataset_true_no_eval.txt'\\n\") \n",
    "            file.write('\\n')\n",
    "            file.write(\"# Experiment 1: fine tune 2 on all false languages. Fin tune 2 half false half true no eval. Eval on eval_lan\\n\") \n",
    "            file.write(\"# Experiment 2: fine tune 2 on all false languages. Fin tune 2 half false half lan from eval_lan in experiment 1. Eval on previous 'true_no_eval'\\n\") \n",
    "            # finetuning 1\n",
    "            file.write(\"python3 preprocessing/take_sentences.py  'languages/f\"+str(i)+\"/dataset_false_lan.txt' 'languages/f\"+str(i)+\"/dataset_false_lan.txt' '17003'\\n\")\n",
    "            # finetuning 2\n",
    "            file.write(\"python3 preprocessing/take_sentences.py  'languages/f\"+str(i)+\"/dataset_false_lan.txt' 'languages/f\"+str(i)+\"/dataset_false_lan_half.txt' '8502'\\n\")\n",
    "            file.write(\"python3 preprocessing/take_sentences.py  'languages/f\"+str(i)+\"/dataset_true_no_eval.txt' 'languages/f\"+str(i)+\"/dataset_true_lan_half_1.txt' '8502'\\n\")\n",
    "            file.write(\"cat 'languages/f\"+str(i)+\"/dataset_false_lan_half.txt' 'languages/f\"+str(i)+\"/dataset_true_lan_half_1.txt' > 'languages/f\" + str(i) +  \"/dataset_fin_tun_2_1.txt'\\n\") \n",
    "            #shuffle\n",
    "            file.write(\"python3 preprocessing/take_sentences.py 'languages/f\" + str(i) +  \"/dataset_fin_tun_2_1.txt' 'languages/f\" + str(i) +  \"/dataset_fin_tun_2_1.txt' '17003'\\n\")\n",
    "            # testing \n",
    "            file.write(\"python3 preprocessing/take_sentences.py 'languages/f\"+str(i)+\"/dataset_eval.txt' 'languages/f\"+str(i)+\"/dataset_eval_1.txt' '4350'\\n\") \n",
    "\n",
    "                #for experiment 2 \n",
    "            #fine_tuning_2  - dataset_false_lan_half.txt\n",
    "            # false group same \n",
    "            file.write(\"python3 preprocessing/take_sentences.py  'languages/f\"+str(i)+\"/dataset_eval.txt' 'languages/f\"+str(i)+\"/dataset_true_lan_half_2.txt' '8502'\\n\")  \n",
    "            file.write(\"cat 'languages/f\"+str(i)+\"/dataset_false_lan_half.txt' 'languages/f\"+str(i)+\"/dataset_true_lan_half_2.txt' > 'languages/f\" + str(i) +  \"/dataset_fin_tun_2_2.txt'\\n\") \n",
    "            #shuffle\n",
    "            file.write(\"python3 preprocessing/take_sentences.py 'languages/f\" + str(i) +  \"/dataset_fin_tun_2_2.txt' 'languages/f\" + str(i) +  \"/dataset_fin_tun_2_2.txt' '17003'\\n\")\n",
    "\n",
    "            # testing\n",
    "            file.write(\"python3 preprocessing/take_sentences.py 'languages/f\"+str(i)+\"/dataset_true_no_eval.txt' 'languages/f\"+str(i)+\"/dataset_eval_2.txt' '4350'\\n\") \n",
    "\n",
    "            file.write('\\n')\n",
    "            # run transformers\n",
    "            # exp1\n",
    "             #fine tuning 1\n",
    "            file.write(\"python3 experiments/SimpleTransformers.py 'languages/f\"+str(i)+\"/dataset_false_lan.txt' 'languages/f\"+str(i)+\"/dataset_eval_1.txt' 'results/output_f\"+str(i)+\"/dataset_\"+str(experiment)+\"/exp1/fine_tuning_1'\\n\")\n",
    "             #fine tuning 2\n",
    "            file.write(\"python3 experiments/SimpleTransformers.py 'languages/f\"+str(i)+\"/dataset_fin_tun_2_1.txt' 'languages/f\"+str(i)+\"/dataset_eval_1.txt' 'results/output_f\"+str(i)+\"/dataset_\"+str(experiment)+\"/exp1/fine_tuning_2'\\n\") \n",
    "            #exp2 -switching true language in fine_tuning_2 and evaluation \n",
    "             #fine tuning 1\n",
    "            file.write(\"python3 experiments/SimpleTransformers.py 'languages/f\"+str(i)+\"/dataset_false_lan.txt' 'languages/f\"+str(i)+\"/dataset_eval_2.txt' 'results/output_f\"+str(i)+\"/dataset_\"+str(experiment)+\"/exp2/fine_tuning_1'\\n\")\n",
    "             #fine tuning 2\n",
    "            file.write(\"python3 experiments/SimpleTransformers.py 'languages/f\"+str(i)+\"/dataset_fin_tun_2_2.txt' 'languages/f\"+str(i)+\"/dataset_eval_2.txt' 'results/output_f\"+str(i)+\"/dataset_\"+str(experiment)+\"/exp2/fine_tuning_2'\\n\")           \n",
    "            #fine tuning 2_2 is false group concatenated with evaluation 1\n",
    "            file.closed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Execution : ___main___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "doe = pd.read_csv(\"doe_features_overview_wiki.csv\") # should it be relative or absolute (relative now and I want to run things from main folder. \n",
    "generate_script_file(doe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
