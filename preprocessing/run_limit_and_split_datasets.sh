# if we want to use KFOLD technique

#for i in $(seq "$1")
#do
#    echo "FOLD" $i "/" $1
#    echo
#python3 take_sentences.py

#AT SOME POINT NEED TO WRITE  IN ALL THE LANGUAGES THAT ARE USED
# arguments: trainingset testset outputdir: !starting with "./"

python3 preprocessing/take_sentences.py 'languages/fr/wikiann-fr.bio' 'languages/fr/train_output.txt' 'languages/fr/test_output.txt' '17003'

python3 preprocessing/take_sentences.py 'languages/de/wikiann-de.bio' 'languages/de/train_output.txt' 'languages/de/test_output.txt' '17003'

python3 preprocessing/take_sentences.py 'languages/el/wikiann-el.bio' 'languages/el/train_output.txt' 'languages/el/test_output.txt' '17003'

python3 preprocessing/take_sentences.py 'languages/nl/wikiann-nl.bio' 'languages/nl/train_output.txt' 'languages/nl/test_output.txt' '17003'

python3 preprocessing/take_sentences.py 'languages/en/wikiann-en.bio' 'languages/en/train_output.txt' 'languages/en/test_output.txt' '17003'

python3 preprocessing/take_sentences.py 'languages/et/wikiann-et.bio' 'languages/et/train_output.txt' 'languages/et/test_output.txt' '17003'

python3 preprocessing/take_sentences.py 'languages/hy/wikiann-hy.bio' 'languages/hy/train_output.txt' 'languages/hy/test_output.txt' '17003'

python3 preprocessing/take_sentences.py 'languages/tr/wikiann-tr.bio' 'languages/tr/train_output.txt' 'languages/tr/test_output.txt' '17003'

python3 preprocessing/take_sentences.py 'languages/sl/wikiann-sl.bio' 'languages/sl/train_output.txt' 'languages/sl/test_output.txt' '17003'

python3 preprocessing/take_sentences.py 'languages/uk/wikiann-uk.bio' 'languages/uk/train_output.txt' 'languages/uk/test_output.txt' '17003'

python3 preprocessing/take_sentences.py 'languages/lt/wikiann-lt.bio' 'languages/lt/train_output.txt' 'languages/lt/test_output.txt' '17003'

python3 preprocessing/take_sentences.py 'languages/pl/wikiann-pl.bio' 'languages/pl/train_output.txt' 'languages/pl/test_output.txt' '17003'

python3 preprocessing/take_sentences.py 'languages/cs/wikiann-cs.bio' 'languages/cs/train_output.txt' 'languages/cs/test_output.txt' '17003'

python3 preprocessing/take_sentences.py 'languages/lv/wikiann-lv.bio' 'languages/lv/train_output.txt' 'languages/lv/test_output.txt' '17003'

python3 preprocessing/take_sentences.py 'languages/sr/wikiann-sr.bio' 'languages/sr/train_output.txt' 'languages/sr/test_output.txt' '17003'

python3 preprocessing/take_sentences.py 'languages/pt/wikiann-pt.bio' 'languages/pt/train_output.txt' 'languages/pt/test_output.txt' '17003'

python3 preprocessing/take_sentences.py 'languages/es/wikiann-es.bio' 'languages/es/train_output.txt' 'languages/es/test_output.txt' '17003'

python3 preprocessing/take_sentences.py 'languages/it/wikiann-it.bio' 'languages/it/train_output.txt' 'languages/it/test_output.txt' '17003'

python3 preprocessing/take_sentences.py 'languages/sq/wikiann-sq.bio' 'languages/sq/train_output.txt' 'languages/sq/test_output.txt' '17003'

python3 preprocessing/take_sentences.py 'languages/ro/wikiann-ro.bio' 'languages/ro/train_output.txt' 'languages/ro/test_output.txt' '17003'

python3 preprocessing/take_sentences.py 'languages/ru/wikiann-ru.bio' 'languages/ru/train_output.txt' 'languages/ru/test_output.txt' '17003'

python3 preprocessing/take_sentences.py 'languages/no/wikiann-no.bio' 'languages/no/train_output.txt' 'languages/no/test_output.txt' '17003'

python3 preprocessing/take_sentences.py 'languages/sv/wikiann-sv.bio' 'languages/sv/train_output.txt' 'languages/sv/test_output.txt' '17003'

python3 preprocessing/take_sentences.py 'languages/hu/wikiann-hu.bio' 'languages/hu/train_output.txt' 'languages/hu/test_output.txt' '17003'

python3 preprocessing/take_sentences.py 'languages/bg/wikiann-bg.bio' 'languages/bg/train_output.txt' 'languages/bg/test_output.txt' '17003'

python3 preprocessing/take_sentences.py 'languages/eu/wikiann-eu.bio' 'languages/eu/train_output.txt' 'languages/eu/test_output.txt' '17003'

python3 preprocessing/take_sentences.py 'languages/br/wikiann-br.bio' 'languages/br/train_output.txt' 'languages/br/test_output.txt' '17003'

python3 preprocessing/take_sentences.py 'languages/fi/wikiann-fi.bio' 'languages/fi/train_output.txt' 'languages/fi/test_output.txt' '17003'

python3 preprocessing/take_sentences.py 'languages/ka/wikiann-ka.bio' 'languages/ka/train_output.txt' 'languages/ka/test_output.txt' '17003'

python3 preprocessing/take_sentences.py 'languages/cy/wikiann-cy.bio' 'languages/cy/train_output.txt' 'languages/cy/test_output.txt' '17003'

python3 preprocessing/take_sentences.py 'languages/tt/wikiann-tt.bio' 'languages/tt/train_output.txt' 'languages/tt/test_output.txt' '17003'
